{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://iamtrask.github.io/2015/07/12/basic-python-network/\n",
    "\n",
    "# my video walking thru this\n",
    "X = np.array([[0,0,1], # 0\n",
    "              [0,1,1], # 1\n",
    "              [1,0,1], # 1\n",
    "              [1,1,1]])# 0\n",
    "\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "syn0 = 2*np.random.random((3,4)) - 1  # (3,4)\n",
    "syn1 = 2*np.random.random((4,1)) - 1  #(4,1)\n",
    "for j in range(6000):\n",
    "    l1 = 1/(1+np.exp(-(np.dot(X,syn0)))) #(4,4)\n",
    "    l2 = 1/(1+np.exp(-(np.dot(l1,syn1)))) #(4,1)\n",
    "    l2_delta = (y - l2)*(l2*(1-l2))\n",
    "    l1_delta = l2_delta.dot(syn1.T) * (l1 * (1-l1))\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += X.T.dot(l1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; np.set_printoptions(suppress=True)\n",
    "\n",
    "def sig(x):\n",
    "  return 1/(1 + np.exp(-x))\n",
    "\n",
    "L1 = np.array([[-10, -5, -5,   5],\n",
    "               [-10,  1, -5,   5],\n",
    "               [  5, -1, 10, -10]])\n",
    "L2 = np.array([[-1],[1],[1],[-1]])\n",
    "\n",
    "H1 = sig(np.dot(X,L1))\n",
    "\n",
    "#array([[0.99330715, 0.26894142, 0.9999546 , 0.0000454 ],    -1    -.99+.26+.99+0=.26  \n",
    "#       [0.00669285, 0.5       , 0.99330715, 0.00669285],     1     0+.5+1+0 = 1.5\n",
    "#       [0.00669285, 0.00247262, 0.99330715, 0.00669285],     1      1\n",
    "#       [0.00000031, 0.00669285, 0.5       , 0.5       ]])   -1    0\n",
    "\n",
    "# Note how L2 is used to manage H2 so that the values come out easy\n",
    "# np.dot(A[0,:],L1[:,0]) \n",
    "H2 = sig(np.dot(H1,L2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "\n",
    "X = torch.tensor([[0,0,1], \n",
    "                  [0,1,1], \n",
    "                  [1,0,1], \n",
    "                  [1,1,1]], dtype=torch.float)\n",
    "\n",
    "y = torch.tensor([[0],[1],[1],[0]])\n",
    "\n",
    "w = torch.tensor(np.ones((3,4)), dtype=torch.float, requires_grad=True)#.retain_grad()\n",
    "w2 = torch.tensor(np.ones((4,1)), dtype=torch.float, requires_grad=True)#.retain_grad()\n",
    "\n",
    "for _ in range(200):\n",
    "  loss = torch.sigmoid(torch.matmul(torch.sigmoid(torch.matmul(X,w)),w2)-y)**2\n",
    "  loss.backward()\n",
    "  with torch.no_grad():\n",
    "    w2 -= .01 * w2.grad\n",
    "    w  -= .01 * w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "X = [[0, 0, 1], \n",
    "     [0, 1, 1], \n",
    "     [1, 0, 1], \n",
    "     [1, 1, 1]]\n",
    "\n",
    "y = torch.tensor([[0],[1],[1],[0]])\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(3,4)\n",
    "        self.linear2 = nn.Linear(4,4)\n",
    "        self.linear3 = nn.Linear(4, 1)\n",
    "    def forward(self, inputs):\n",
    "        out = F.relu(self.linear1(inputs))\n",
    "        out = self.linear2(out)\n",
    "        out = self.linear3(out)\n",
    "        log_probs = torch.sigmoid(out)\n",
    "        return log_probs\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.BCELoss()\n",
    "model = SimpleModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "for epoch in range(1000):\n",
    "    total_loss = 0\n",
    "    for idr, row in enumerate(X):\n",
    "        model.zero_grad()\n",
    "        log_probs = model(torch.tensor(row,dtype=torch.float))\n",
    "        loss = loss_function(log_probs, torch.tensor(y[idr], dtype=torch.float).resize_((1)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "\n",
    "#check to see if it learned.\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "  model(torch.tensor(X[0],dtype=torch.float))\n",
    "  model(torch.tensor(X[1],dtype=torch.float))\n",
    "  model(torch.tensor(X[2],dtype=torch.float))\n",
    "  model(torch.tensor(X[3],dtype=torch.float))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
